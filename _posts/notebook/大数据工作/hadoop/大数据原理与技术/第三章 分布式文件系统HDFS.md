## 第三章 分布式文件系统
### 写在章节前面的话
1. 本章的组织结构:
	1. 分布式文件系统的的基本概念
	2. 结构和设计需求
	3. 介绍HDFS
	4. HDFS的编程实践
### 3.1 分布式文件系统
1. 分布式文件系统一般采用"客户端/服务器"模式,客户端以特定的通信协议通过网络与服务器建立连接,提出文件访问请求
#### 3.1.1 计算机集群
1.  计算机集群的基础架构
	1. 集群中的计算机节点存放在机架上,每个机架可以存放8-64个节点
	2. 同一个机架的不同的节点之间可以通过网络会连
	3. 多个不同的之间可以采取另一极网络和交换机互联
	4. 示意图:
	![计算机集群架构](https://lh3.googleusercontent.com/M3PdxjJp57F5K1DrndYIyl2YEYjpmwNT3EsjTBh5epagHEDF3IvnYwgWgfDdF1vsPJGKieLoY6J8 "计算机集群架构")
#### 3.1.2 分布式文件系统的结构
 1. Windows和Linux等操作系统一般会把磁盘空间划分为每512字节一组,成为"磁盘块",它是文件系统读写操作的最小单位,文件系统的块(Block)通常是磁盘块的整数倍,即每次读写的数量必须磁盘块大小的整数倍.
 2. 分布式文件系统也采用了块的概念,文件被分为若干个块进行存储.HDFS默认的一个块大小是64MB.
 3. 与普通文件系统不同的是,在分布式文件系统中,如果一个文件小于一个块的大小,它并不占用整个数据块的存储空间.
 4. 分布式文件系统的物理结构
	 1. "主节点"或者"名称节点":
		 1. 负责文件和目录的创建,删除和重命名等
		 2. 同时管理者数据节点和文件块的映射关系 
	 2. "从节点"或者"数据节点": 
		 1. 数据节点负责数据的存储和读取,在存储是,由名称节点分配位置,然后客户端直接把数据写入相应的数据的节点;在读取时,客户端从名称节点获得数据节点和文件块的映射关系,然后就可以到相应的位置访问文件块.
		 2. 数据节点也要根据名称节点的命令创建,删除数据和冗余控制.
	3. 图 3-2
![分布式文件系统的整体架构](https://lh3.googleusercontent.com/IyNIYap9mcNq6P22MfohbHH0d195Qx0zZK2VS1dnbba_SlRrQY2VlVoRJHs6k9PuZZroTLpqvseH "分布式文件系统的整体架构")
5. HDFS 主要用于处理大规模文件,如TB级文件.处理过小的文件不仅无法充分发挥其优势,会严重影响到系统的扩展和性能
#### 3.1.3 分布式文件系统的设计需求
1. 分布式文件系统的设计目标:
		1. 透明性
		2. 并发性
		3. 可伸缩性
		4. 容错
		5. 安全需求
2.  表 3-1
![分布式文件系统设计需求](https://lh3.googleusercontent.com/o53pjjoEhnptZGJPODknBOXTFm_j0bh1bE8gG6_i7FBsDtFsfGDuRvcAlww5O36eo_o1h5kKzGxk "分布式文件系统设计需求")

### 3.2 HDFS 简介
1. HDFS实现的目标
	1. 兼容廉价的硬件设备
	2. 流数据读写.
		1. 普通文件系统主要用于随机读写和用户交互.
		2. HDFS 为了满足批量数据的处理要求而设计的,因此为了提高数据的吞吐率,HDFS放松了一些POSIX的要求,从而能够以流式方式来文件的系统数据.
		3. 大数据集
		4. 简单的文件模型.HDFS采取了"一次写入,多次读取"简单文件模型,文件一旦完成写入,关闭后无法再次写入,只能读取.
		5. 强大的跨平台性 
2. HDFS 的局限性
	1. 不适合低延时的数据访问.采取流式数据读取,具有很高的数据吞吐率,但是这也意味着较高的延时.
	2. 无法高效的存储大量小的文件.
		1. 名称节点元数据较多,元数据检索的效率变低.影响文件系统的扩展性.
		2. MapReduce处理大量小文件时,会产生过多Map任务,线程的开销的大大增加.
		3. 访问大量小文件的速度远远低于访问几个大文件的速度,因为访问大量的小文件,需要不断从一个数据节点调到另一个数据节点,严重影响性能
	3. 不支持多用户写入及任意修改文件.HDFS只允许一个有一个写入者,不允许多个用户对同一个文件进行写操作,而且只允许对文化进行追加操作,不能执行随机写操作.
 ### 3.3 HDFS的相关概念
#### 3.3.1 块
1.  HDFS寻址开销不仅包括磁盘寻道开销,还包括数据块的定位开销.
	1. 设计一个较大的块,可以将上述寻址开销分摊到较多的数据中,降低单位数据的寻址开销
	2. 块的大小也不宜过大,因为MapReduce中的Map任务一次只处理一个块的数据,如果启动的任务过少,就会降低作业的并行程度. 
2. 采用抽象的块的概念的原因:
	1. 支持大规模文件存储
	2. 简化系统的设计.
		1. 简化了存储管理
		2. 方便元数据的管理,元数据不需要和文件块一起存储,可以由其他系统负责管理元数据 
#### 3.3.2 名称节点和数据节点
1. 名称节点
	1. 名称节点负责管理分布式文件系统的命名空间(Namespace),保存了两个核心数据结构即FsImage和EditLog.
	2. FsImage用于维护文件系统以及文件树中的所有文件和文件夹的元数据
	3. 操作日志EditLog记录了所有针对文件创建.删除.重命名等操作.
	4. 名称节点记录了每个文件中各个块所在的数据节点的位置信息,但并不是持久化存储这些信息,而是系统每次启动时扫描所有数据节点重构得到这些信息.具体过程大致如下:
		1. 名称节点启动时,会将FSImage的内容加载到内存中,然后执行EditLog文件中的各种操作,使内存中的元数据保持最新.
		2. 这个操作完成之后,就会创建一个新的FsImage文件和一个空的EditLog文件.
		3. 名称节点启动后成功进入正常运行状态之后,HDFS中的更新操作都会被写入EditLog,而不是写入FSImage.
			1. 对于3这样做的原因: 这是因为对于分布式文件系统而言,FsImage通常很庞大(一般GB级别以上),如果所有操作都直接往FsImage文件中添加,那么系统会变得缓慢.
			2. 相对而言,EditLog通常都远远小于FsImage,更新操作写入EditLog是非常有效的.
		4. 名称节点在启动过程处于"安全模式",只能对外提供读操作,无法提供写操作.
		5. 启动过程结束后,系统就会退出安全模式,进入正常运行状态,对外提供写操作.
	5.  图3-3
	![名称节点的数据结构](https://lh3.googleusercontent.com/hjynAU38MLKLdYfNIrfQFb02dICHqQcRiBz-c4toD1zZc36kiJv-W7X4VX6licfDw15jH6Am5s8m "名称节点的数据结构")
2.  数据节点
	1. 是分布式文件系统HDFS的工作节点,负责数据的存储和读取
	2. 会根据客户端或者名称节点的调度来进行数据存储和检索,并且名称节点定期发送自己所存储块的列表.
	3. 每个数据节点的数据会保存在各自节点本地Linux文件系统中.
#### 3.3.3第二名称节点
1. 第二名称节点用于解决:
	1. 如果EditLog很大,就会导致整个过程变得非常缓慢,使得名称节点处于"安全模式",无法正常对外提供写操作.
2. 功能:
	1.  可以完成EditLog和FsImage的合并操作,减少EditLog的大小,缩短名称节点的重启时间
	2. 作为名称节点的"检查点",保存名称节点的元数据信息.
3. 如何实现以上两个功能
	1. EditLog与FsImage的合并操作. 
	2. 作为名称节点的检查点.
		1. 会丢失部分元数据信息,在HDFS的设计中也不支持把系统直接切换到第二名称节点,从这个角度来说,第二名称节点只是起到了名称节点"检查点"作用,并不能起到热备份的作用. 
	3. 图3-4 第二名称节点的工作的示意图
	![第二名称节点的工作示意图](https://lh3.googleusercontent.com/A98rOidgyTLpIRB-ZEgUPv6ySq-Lrku6KNBSkLh4LsivQF3e94Zf5lQ3rd0sAi5Rz8i0tJ9dSa-S "第二名称节点的工作示意图")
### 3.4 HDFS体系结构
1. 本小节主要内容:
	1. 简要介绍HDFS的体系结构
	2. HDFS的命名空间
	3. 通信协议
	4. 客户端
	5. HDFS的体系结构的局限性
#### 3.4.1 概述
1. HDFS 采取了(Master/Slave)结构模型,一个HDFS的集群包括一个名称节点和若干个数据节点
2. 名称节点作为中心服务器,负责管理文件系统的命名空间及客户端对文件的访问
3. 集群中数据节点一般是一个节点运行一个数据节点的进程,负责处理文件系统客户端的读/写请求,在名称节点的统一调度下进行数据块的创建,删除和复制操作.每个数据节点的数据实际上保存在本地的Linux文件系统中.
4. 每个数据节点会定期向名称节点发送"心跳"信息,报告自己的状态,没有按时发送心跳信息的数据节点会被标记为"宕机",t不会在发送任何I/O请求.
5. 图3-5
![HDFS的体系结构](https://lh3.googleusercontent.com/SS3Zx6AOx9mXRC0DW47Y7gQE5U7w5qMpRSKKobAlhL4NRmPjU2zsP6X77sw_9mw_qagk9CDVHDN1 "HDFS的体系结构")
6. 在系统内部,一个被切分为若干数据块,这些数据块被分布存储到若干个数据节点上.
	1. 当客户端需要访问一个文件时,首先把文件名发送到名称节点,名称节点根据文件名找到相应数据块(一个文件中可能包含多个数据块),
	2. 再根据每个数据块的信息找到实际存储各个数据块的数据节点的位置,并把数据节点的位置,并把数据节点的位置发送到客户端.
	3. 客户端直接访问数据节点获取数据.
7.  HDFS集群中只有唯一一个名称节点,该节点负责所有元数据的管理,
	1. 这种设计简化了系统的结构,
	2. 可以保证数据不会脱离名称节点的控制,
	3. 用户数据也永远不会经过名称节点,这样大大减轻了中心服务器的负担,方便了数据管理.
#### 3.4.2 HDFS命名空间
1. HDFS 命名空间包含目录.文件和块
2. 命名空间管理是指命名空间支持对HDFS中的目录、文件和块做出类似文件系统的创建、修改、删除等基本操作。
3. 整个集群只有一个命名空间，并且只有唯一一个名称节点，该节点负责对这个名称空间进行管理。
4. HDFS使用的是分级的文件系统，用户可以像普通文件系统一样，创建、删除目录和文件，在目录间转移目录，重命名文件等
5. HDFS还没有实现磁盘配额和文件访问权限控制功能，也不文件的硬链接和软连接（快捷方式）。
#### 3.4.3 通信协议
1. 所有HDFS通信协议都是构建在TCP/IP协议的基础之上
	1. 客户端通过一个可配置的端口号向名称节点主动发起TCP连接，并使用客户端协议与名称节点进行交互。
	2. 名称节点和数据节点之间则使用数据节点协议进行交互。
	3. 客户端与数据节点通过RPC来实现的。
	4. 名称节点不会主动发起RPC，而是响应来自客户端和数据节点的RPC请求。
#### 3.4.4 客户端
1. 客户端是用户操作HDFS的常用方式
2. 客户端可以支持打开、读取、写入等常见操作，提供了以shell的方式访问HDFS的数据。
3. 此外，HDFS也提供了Java API ,作为应用程序访问文件系统的客户端编程接口。
#### 3.4.5 HDFS体系结构的局限性
1. HDFS只设置一个名称节点，这样做虽然简化了系统设计，但也带来了明显的缺陷。
	1. 命名空间的限制
	2. 性能瓶颈
	3. 隔离问题，只有一个名称节点，只有一个命名空间，因此无法对不同的应用程序进行隔离
	4. 集群可以性
### 3.5 HDFS的存储原理
1. 本节知识组织：
	1. 数据冗余存储
	2. 数据的存储策略
	3. 数据错误和恢复
#### 3.5.1 数据的冗余存储
1. 目的：为了系统的容错性和可用性
2. 方式：数据的多副本存储，通常一个数据块的多个副本会被分布到不同的数据节点上。
3. 图3-6
![HDFS多副本存储](https://lh3.googleusercontent.com/v91vCXbzyCDiQwE_sBGsjjEfspf9u-8tjshAAx1sgnNHG1TMNUVmz3BtGTo_rywj4yQsOYd1pYkl "HDFS多副本存储")
4. 优点：
	1. 加快数据传输速度
	2. 容易检查数据错误
	3. 保证数据可靠性
#### 3.5.2 数据存取策略
1. 数据存取策略：
	1.  数据存放
	2. 数据读取
	3. 数据复制
2. 数据存放:
	1. HDFS默认每个数据节点都在不同的机架上
		1. 缺点：不能充分利用同一个机架内部机器之间的带宽。
		2. 优点：
			1. 很高的数据可靠性
			2. 可以并行的读取数据
			3. 更容易实现系统内部的负载均衡和错误处理
	2. HDFS默认的冗余存储复制因子是3，每一个文件块会被同时保存在三个地方。这样既可以保证机架发生异常时的数据恢复，也可以提高数据读写的性能
	3. 图 3-7
![副本的放置策略](https://lh3.googleusercontent.com/jgAYecXBl-UGgb2q3A0qPw0GJ3jqKmyYYI86P5yGVOp5AuQ7rI-P66JdfkmVryyAhohfZf5AlL1Z "副本的放置策略")
	4. 关于上图的解释：
		1.  如果是集群内发起的写操作请求，则把第一副本放置在发起写操作请求的数据节点上，就近写入数据。
		2. 如果是来自集群外部写操作请求，则从集群内部挑选一个磁盘不太满，CPU不太忙的数据节点作为第一副本的存放地
3. 数据读取
	1. HDFS 提供了一个API可以确定一个数据节点的所属机架的ID，客户端也可以调用API获取自己所属的机架ID。
	2. 当客户端读取数据数据时，从名称节点获得数据块的不同副本的存放位置表，列表中包含了副本所在数据节点所在的数据节点，可以通过API来确定客户端和这些数据节点所属的机架ID。
	3. 当发现数据块副本的ID和客户端对应的机架ID相同时，就优先选择该副本读取数据，如果没有发现，就随机选择一个副本读取数据。
4. 数据复制
	1. HDFS数据复制采用了流水线的复制策略，大大提高了数据复制的效率
	2. 具体过程：
		1. 当客户端要向HDFS中写入一个文件时，这个文件会被写入本地，并被切分为若干个块。
		2. 每个块都向HDFS的名称节点发出写请求，名称节点会根据系统各个数据节点的使用情况，选择一个数据节点的列表返回给客户端
		3. 客户端把数据写入第一个数据节点，同时把列表传给第一个节点
		4. 当第一个数据节点接收到数据，写入本地，并向列表中第二个数据节点发起连接请求，把自己接受到数据和列表传到第二数据节点。
		5. 当第二数据节点接到数据，写入本地，并向第三数据发起连接请求，以此类推，列表中的多个数据数据节点形成一个数据复制的流水线。
		6. 当文件写完的时候，数据复制也同时完成。
#### 3.5.3 数据错误和恢复
1. 名称节点出错
	1. 把名称节点上的元数据信息，同步到其他的文件系统，比如远程挂载的网络文件系统NFS
	2. 运行一个第二名称节点
	3.  结合两种方式使用，当名称节点宕机时，首先远程挂载网络文件系统的获得元数据信息，放到第二名称节点进行恢复，并把第二名称节点作为名称节点使用
2. 数据节点出错
	1. 数据节点定期向名称节点发送“心跳”信息，向名称节点汇报自己的状态。
	2. 当数据节点发送故障，或者网络发生断网时，这些数据节点无法发送“心跳”信息，这些数据节点被标记为“宕机”，节点上面的所有数据会被标记为“不可读”，名称节点不会再向它发布任何I/O信息。
	3. 如果数据的块副本数量小于冗余因子，就会启动数据的冗余复制，为它生成新的副本。
3. 数据出错
	1. 网络传输或磁盘错误等因素会造成数据错误。
	2. 客户端读取到数据数据后，会采取md5和sha1来对数据块进行校验。
	3. 在文件创建的时候，客户端就会对每一个文件块进行信息摘录，并把这些信息写入同一路径的隐藏文件里面。
	4. 当客户端读取文件的时候，会先读取文件的信息文件，然后利用该信息文件对每个读取的数据块进行校验，
	5. 如果校验出错，客户端就会请求另外一个数据节点读取该文件块，并向名称节点报告这个文件有错误，名称节点会定期检查并且复制这个块
#### 3.6 HDFS的数据读写过程
1. HDFS读写相关的类
	1. FileSystem是一个通用文件系统的抽象基类，可以被分布式系统继承，所有可能使用Hadoop文件的代码都要使用这个基类
	2. Hadoop为这个FileSystem抽象类提供了很多具体实现。
		1. DistributedFileSystem就是FileSystem在HDFS文件系统的实现。
2. FileSystem的open（）方法返回的是一个输入流FSDataInputStream
	1. 在HDFS中文件系统中具体的输入流是DFSInputStream对象 
3. FileSystem的create（）方法返回就是一个输出流FSDataOutputStream
	1. 在HDFS文件系统中具体的输出流就是一个DFSOutputStream
#### 3.6.1 读取数据的过程
1. 客户端连续调用open()、read()、close()读取数据时，HDFS内部的执行过程如下
2. 图3-8
![HDFS读取数据的过程](https://lh3.googleusercontent.com/3KARNokoek4svM_jwyhdj-VKt8CUFePCZ8WCw-0L1lqz-vTtVd8UiLpCrKOCTbM3ck1cl0_dOFwQ "HDFS读取数据的过程")
3. 关于上图的注释：
	1. 如果客户端与数据节点通信出现错误，就会尝试连接包含此数据块的下一个数据节点。
#### 3.6.2 写数据的过程
1. 客户端在连续调用create()、write()和close()时,HDFS内部的执行过程。
2. 图3-9
![HDFS的写数据过程](https://lh3.googleusercontent.com/f4berO9Yq7JU9LPc6NfXiMXgh2cd-IMygYYpBNGRH8oFnlskXHaulGLbZGaYsLpAuKjVtx1_VMTM "HDFS的写数据过程")
3. 对于上图的注释：
	1. 对于第二步而言：DistributedFileSystem通过RPC远程过程调用名称节点，在文件系统的命名空间创建一个新的文件。名称节点会执行一些检查，比如此文件是否以及存在，客户端是否有权限创建文件等。检查通过之后，名称节点会创建一个新文件，并添加文件信息。远程过程调用结束后，DistributedFileSystem会利用DFSoutputStream来实例化FSDataOutputStream,返回客户端，客户端使用这个输出流写入数据。
	2. 对于其它步的解释：如图所示
	![HDFS写数据过程详细解释](https://lh3.googleusercontent.com/edQBiCTgKqQRVCS9UjZ8agH6pVpBWPZR90YmN7nMitTpXyY5OYIm5yX7W2qcsxBP8BN1s_vnS8Mb "HDFS写数据过程详细解释")
###  3.7 HDFS的编程实践
1. shell 编程
	1. [shell编程的官方文档](http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/FileSystemShell.html) 
	2. [localhost:50070是HDFS的web地址](http://localhost:50070)
2. Java API 编程
	1. shell命令本质上，就是JavaAPI的应用
### 3.8 补充
1. NameNode 机制
	1. 为了提高效率，namenode便将元数据加载到内存，而不是直接修改文件，同时会记录下操作日志，供后期修改文件使用。
	2. NameNode对数据的管理涉及到了3种存储形式：
		1. 内存数据
		2. 元数据文件
		3. 操作日志文件
	3. NameNode内存示意图：
	![NodeNode内存示意图](https://lh3.googleusercontent.com/NFDog2qRktTx51JHrOYtW7L9JNGAor49-XEsFwKR9MPIHI_Ay-0x58_02BuK6JrfvHR-cGceU5L4 "NodeNode内存示意图") 
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTM3MTk1MjYxNiwyMDc0NjM0ODI4LC01MT
MyNDkxNTQsLTE4MTczNjg0MjQsLTYxNzc0NTg4NiwxMTMzNjUx
MjMsLTQwNjgyODUwOSwtMTc5ODU1NjUzMSw5MjAxNjUyNDksMT
E2MTE3NDgyNiw5MTQ3Mzg1ODAsOTgxODA1NzQ4LC0xNDI5Mzc1
Nzg3LDcyMjY2NTI0NCw1NDI4NzUyNzEsMTY2NDk2MDgwMSw1MD
g5MDcxNjIsMTQzMDQwMTEwMywtNTYyODAyMDc1LDExNDc2MTI2
OV19
-->